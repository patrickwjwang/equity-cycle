{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99889a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.patches import Patch\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# Set directories\n",
    "notebook_dir = os.getcwd()\n",
    "base_dir = os.path.join(notebook_dir, '..')\n",
    "data_dir = os.path.join(base_dir, 'data', 'processed')\n",
    "raw_data_dir = os.path.join(base_dir, 'data', 'raw')\n",
    "src_dir = os.path.join(base_dir, 'src')\n",
    "graph_dir = os.path.join(base_dir, 'results', 'graphs')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# Ignore future warning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1847658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for creating factors\n",
    "def create_factors(feature_path = 'credit_risk_', feature_name = \"credit_factor\", pct = 0.2):\n",
    "    '''\n",
    "    feature_path: first part of the csv file name\n",
    "    feature_name: name of the feature column\n",
    "    pct: percent quantile for high and low partition\n",
    "    \n",
    "    function returns data frame of features for all cycles\n",
    "    '''\n",
    "    \n",
    "    for i in range(4):\n",
    "        # read processed data files\n",
    "        csv_string = feature_path + str(i + 1) + '.csv'\n",
    "        feature_df = pd.read_csv(os.path.join(data_dir, csv_string))\n",
    "        # drop empty columns\n",
    "        feature_df = feature_df.loc[:, ~feature_df.columns.str.startswith('Unnamed')]\n",
    "        price_string = 'price_' + str(i + 1) + '.csv'\n",
    "        price_df = pd.read_csv(os.path.join(data_dir, price_string))\n",
    "        # create year column\n",
    "        temp_df = feature_df.copy()\n",
    "        temp_df['Year'] = pd.DatetimeIndex(feature_df['Date']).year\n",
    "        temp_price = price_df.copy()\n",
    "        temp_price['Year'] = pd.DatetimeIndex(temp_price['Date']).year\n",
    "        # average feature value by year\n",
    "        yearly_feature = temp_df.groupby(['Year']).mean()\n",
    "        yearly_feature = yearly_feature.transpose()\n",
    "        unique_yrs = temp_df['Year'].unique()\n",
    "        n_yrs = len(unique_yrs)\n",
    "        n_stocks = len(yearly_feature.index)\n",
    "        n = int(n_stocks * pct)\n",
    "\n",
    "        for idx, year in enumerate(unique_yrs):\n",
    "            # stocks with lowest and highest feature values for the year\n",
    "            low_stocks = yearly_feature.iloc[:, idx].sort_values().index.values[0:n]\n",
    "            high_stocks = yearly_feature.iloc[:, idx].sort_values().index.values[(n_stocks - n):n_stocks]\n",
    "            # stock prices of stocks with lowest feature value\n",
    "            low_price = temp_price[temp_price['Year'] == year][np.append(low_stocks, \"Date\")]\n",
    "            # stock prices of stocks with highest feature value\n",
    "            high_price = temp_price[temp_price['Year'] == year][np.append(high_stocks, \"Date\")]\n",
    "\n",
    "            if year != max(unique_yrs):\n",
    "                # add stock prices of the \"first day\" of the next year for return calculation\n",
    "                low_price = pd.concat( \n",
    "                    [\n",
    "                        low_price, \n",
    "                        temp_price[temp_price['Year'] == (year + 1)][np.append(low_stocks, \"Date\")].head(1)\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                # add stock prices of the \"first day\" of the next year for return calculation\n",
    "                high_price = pd.concat( \n",
    "                    [\n",
    "                        high_price, \n",
    "                        temp_price[temp_price['Year'] == (year + 1)][np.append(high_stocks, \"Date\")].head(1)\n",
    "                    ]\n",
    "                )\n",
    "             # save date column\n",
    "            temp_dates = low_price['Date'][1:]\n",
    "            # calculate returns and take average across stocks (rows)\n",
    "            temp_returns_low = low_price.drop(\n",
    "                columns = ['Date']\n",
    "            ).pct_change().iloc[1:, :].mean(axis = 1).to_frame(name = feature_name)\n",
    "            # calculate returns and take average across stocks (rows)\n",
    "            temp_returns_high = high_price.drop(\n",
    "                columns = ['Date']\n",
    "            ).pct_change().iloc[1:, :].mean(axis = 1).to_frame(name = feature_name)\n",
    "            # return of high credit risk - return of low credit risk\n",
    "            temp_returns = temp_returns_high.sub(temp_returns_low)\n",
    "            temp_returns['Date'] = temp_dates\n",
    "            if idx == 0:\n",
    "                returns_df = temp_returns\n",
    "            else:\n",
    "                returns_df = pd.concat([returns_df, temp_returns])\n",
    "        if i == 0:\n",
    "            daily_returns = returns_df\n",
    "        else:\n",
    "            daily_returns = pd.concat([daily_returns, returns_df])\n",
    "    return daily_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f984fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create credit factors\n",
    "credit_factors = create_factors(feature_path = 'credit_risk_', feature_name = \"credit_factor\", pct = 0.2)\n",
    "credit_factors.to_csv(os.path.join(data_dir, \"credit_factor_daily.csv\"))\n",
    "\n",
    "# create turnover factors\n",
    "turnover_factors = create_factors(feature_path = 'turnover_', feature_name = \"turnover_factor\", pct = 0.2)\n",
    "turnover_factors.to_csv(os.path.join(data_dir, \"turnover_factor_daily.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e90b180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
